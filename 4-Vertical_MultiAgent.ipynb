{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Optional\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from abc import ABC, abstractmethod\n",
    "from colorama import Fore\n",
    "from exec_code import execute_code, extract_code_from_string\n",
    "from prompt import CODE_DEVELOPER_SYSTEMPROMPT, COORDINATOR_SYSTEMPROMPT, CRITIC_ROLE_PROMPT, EXECUTE_UIDESIGN_SYSTEMPROMPT, OPTIMIZER_SYSTEMPROMPT, TESTER_SYSTEMPROMPT\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class Agent(ABC):\n",
    "    \n",
    "    def __init__(self, \n",
    "        model: Optional[str] = None, \n",
    "        system_prompt: Optional[str] = None\n",
    "    ) -> None:\n",
    "        \n",
    "        model = model if model else os.getenv(\"OPENAI_DEFAULT_MODEL\")\n",
    "        \n",
    "        self.memory = []\n",
    "        self.model = model\n",
    "        \n",
    "        if system_prompt:\n",
    "            self.memory.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    def add_to_memory(self, role, message):\n",
    "        self.memory.append({\"role\": role, \"content\": message})\n",
    "\n",
    "    def get_schema(self):\n",
    "        return self.function\n",
    "        \n",
    "    @abstractmethod\n",
    "    def run(self,prompt):\n",
    "        \"\"\"User must define this method. Run the agent\"\"\"\n",
    "    \n",
    "class ConversationAgent(Agent):\n",
    "    \n",
    "    def __init__(self, \n",
    "        model: Optional[str] = None, \n",
    "        system_prompt: Optional[str] = None,\n",
    "        name_agent: Optional[str] = None,\n",
    "        description: Optional[str] = None\n",
    "    ) -> None:\n",
    "        super().__init__(model,system_prompt)\n",
    "\n",
    "        self.name_agent = name_agent\n",
    "        self.description = description\n",
    "\n",
    "        self.function={\n",
    "            \"name\": self.name_agent,\n",
    "            \"description\": self.description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"user_prompt\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"User prompt to the agent\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"user_query\"]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def run(self,prompt):\n",
    "\n",
    "        self.add_to_memory(\"user\", prompt)\n",
    "        completion=''\n",
    "        stream = client.chat.completions.create(\n",
    "            messages=self.memory,\n",
    "            model=self.model,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        for chunk in stream:\n",
    "            text_chunk=chunk.choices[0].delta.content\n",
    "            if text_chunk:\n",
    "                completion+=text_chunk\n",
    "                print(text_chunk, end='', flush=True)\n",
    "        \n",
    "        self.add_to_memory(\"assistant\", completion)\n",
    "        \n",
    "        return completion\n",
    "\n",
    "class CodeExecuterAgent(Agent):\n",
    "\n",
    "    def __init__(self, \n",
    "        model: Optional[str] = None, \n",
    "        system_prompt: Optional[str] = None,\n",
    "        name_agent: Optional[str] = None,\n",
    "        description: Optional[str] = None\n",
    "    ) -> None:\n",
    "        super().__init__(model,system_prompt)\n",
    "\n",
    "        self.name_agent = name_agent\n",
    "        self.description = description\n",
    "\n",
    "        self.function={\n",
    "            \"name\": self.name_agent,\n",
    "            \"description\": self.description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"user_prompt\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"User prompt to the agent\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"user_query\"]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def run(self,prompt):\n",
    "\n",
    "        completion=''\n",
    "        code_exec_result=''\n",
    "        code_to_execute = extract_code_from_string(prompt)\n",
    "        if code_to_execute:\n",
    "            try:\n",
    "                print(\"Executing code...\")\n",
    "                exec_response = execute_code(code_to_execute,use_docker=False)\n",
    "                if exec_response[0] == 0:\n",
    "                    print(f\"Code executed successfully\")\n",
    "                    code_exec_result=f'{prompt}\\n\\nCode executed successfully'\n",
    "                else:\n",
    "                    print(f\"Error executing code: {exec_response[1]}\")\n",
    "                    code_exec_result=f'{prompt}\\n\\nError executing code: {exec_response[1]}'\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing code: {e}\")\n",
    "                code_exec_result=f'{prompt}\\n\\nError executing code: {e}'\n",
    "        else:\n",
    "            print(f\"No code found to execute.\")\n",
    "            prompt+=f'{prompt}\\n\\nError executing code: bad format'\n",
    "        \n",
    "        prompt+=code_exec_result\n",
    "        \n",
    "        self.add_to_memory(\"user\", prompt)\n",
    "        \n",
    "        stream = client.chat.completions.create(\n",
    "            messages=self.memory,\n",
    "            model=self.model,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        for chunk in stream:\n",
    "            text_chunk=chunk.choices[0].delta.content\n",
    "            if text_chunk:\n",
    "                completion+=text_chunk\n",
    "                print(text_chunk, end='', flush=True)\n",
    "        \n",
    "        self.add_to_memory(\"assistant\", completion)\n",
    "        \n",
    "        return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AgentManager(Agent):\n",
    "    \n",
    "    def __init__(self, \n",
    "        model: Optional[str] = None, \n",
    "        system_prompt: Optional[str] = None,\n",
    "        list_agents: Optional[list] = None,\n",
    "        max_iteration: Optional[int] = 10\n",
    "    ) -> None:\n",
    "        super().__init__(model,system_prompt)\n",
    "        \n",
    "        self.list_agents=list_agents\n",
    "        self.max_iteration=max_iteration\n",
    "    \n",
    "    def get_agent_list_schemas(self):\n",
    "        return [agent.get_schema() for agent in self.list_agents]   \n",
    "    \n",
    "    def run(self,prompt):\n",
    "        \n",
    "        print(Fore.MAGENTA,f\"----------------- RUN MANAGER -----------------\")\n",
    "        print(f\"Manager: I'm thinking the best agent to solve the user query -> {prompt}\")\n",
    "        \n",
    "        # Choose what agent i have to execute to resolve the problem\n",
    "        messages = self.memory + [{\"role\": \"user\", \"content\": f\"[PROMPT]\\n{prompt}\\n\\n[AGENTS]\\n{self.get_agent_list_schemas()}\"}]\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=self.model,\n",
    "            functions=self.get_agent_list_schemas()\n",
    "        )\n",
    "        \n",
    "        # Get the agent to execute\n",
    "        solver_agent_name=chat_completion.choices[0].message.function_call.name\n",
    "        solver_agent_prompt=json.loads(chat_completion.choices[0].message.function_call.arguments)['user_prompt']\n",
    "        \n",
    "        print(f\"Manager: the best agent to solve this is -> {solver_agent_name}\")\n",
    "        self.add_to_memory(\"user\", solver_agent_prompt)\n",
    "        \n",
    "        #get the class agent to execute\n",
    "        solver_agent_class = next((agent for agent in self.list_agents if agent.name_agent == solver_agent_name), None)\n",
    "        \n",
    "        # Se crea una nueva lista para alamacenar los agentes que actuarÃ¡n como revisores\n",
    "        reviewers_agents = self.list_agents.copy()\n",
    "        \n",
    "        # Se elimina el agente solver de la lista de revisores\n",
    "        reviewers_agents.remove(solver_agent_class)      \n",
    "        \n",
    "        main_proposal = solver_agent_prompt\n",
    "        \n",
    "        feedback=''\n",
    "\n",
    "        base_colors = [Fore.CYAN, Fore.YELLOW, Fore.BLUE]\n",
    "        \n",
    "        # Steps to execute\n",
    "        for i in range(self.max_iteration):\n",
    "            \n",
    "            print(Fore.MAGENTA,f\"\\n\\n-----------------> ITERATION: {i+1}\")\n",
    "            \n",
    "            # press enter to continue\n",
    "            #input(\"Press Enter to continue...\")\n",
    "            \n",
    "            agree_agents = 0\n",
    "            for index, reviewer_agent in enumerate(reviewers_agents):\n",
    "                \n",
    "                # If we didn't get agreement from all agents, solver gets a chance to update the proposal\n",
    "                if \"Code is fine\" in feedback:\n",
    "                    agree_agents += 1\n",
    "                else:\n",
    "                    print(Fore.GREEN, f\"\\n\\nAgent Solver -> {solver_agent_class.name_agent} is proposing a solution\")\n",
    "                    # El solver_agent comienza con una propuesta inicial\n",
    "                    main_proposal = solver_agent_class.run(f\"{main_proposal}\")\n",
    "                    agree_agents = 0\n",
    "                    \n",
    "                # Colores base de Colorama\n",
    "                color = base_colors[index % len(base_colors)]\n",
    "                \n",
    "                print(color,f\"\\n\\nFeedback from: {reviewer_agent.name_agent}\")\n",
    "\n",
    "                # Cada agente revisor proporciona su retroalimentaciÃ³n\n",
    "                feedback = reviewer_agent.run(f'{main_proposal}. {CRITIC_ROLE_PROMPT}')\n",
    "\n",
    "                # AÃ±ade la retroalimentaciÃ³n a la memoria del solver_agent\n",
    "                solver_agent_class.add_to_memory(\"user\", f\"{reviewer_agent.name_agent}: {feedback}\")\n",
    "                \n",
    "                print(f'len(reviewers_agents): {len(reviewers_agents)}')\n",
    "                print(f'agree_agents: {agree_agents}')\n",
    "            \n",
    "            if agree_agents >= len(reviewers_agents):\n",
    "                break\n",
    "                    \n",
    "        print(Fore.MAGENTA, f\"Manager: Consensus reached with all agents!!!\")\n",
    "        print(f\"Manager: the final solution is -> \\n\\n{main_proposal}\")\n",
    "        \n",
    "        return main_proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CodeDeveloper=ConversationAgent(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    name_agent=\"CodeDeveloper\",\n",
    "    description=\"Agent to create code in python\",\n",
    "    system_prompt=CODE_DEVELOPER_SYSTEMPROMPT\n",
    ")\n",
    "\n",
    "UIDesignDeveloper=ConversationAgent(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    name_agent=\"UIDesignDeveloper\",\n",
    "    description=\"Agent to resolve UI design problems in python\",\n",
    "    system_prompt=EXECUTE_UIDESIGN_SYSTEMPROMPT\n",
    ")\n",
    "\n",
    "TesterDeveloper=CodeExecuterAgent(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    name_agent=\"TesterDeveloper\",\n",
    "    description=\"Agent to execute and test code\",\n",
    "    system_prompt=TESTER_SYSTEMPROMPT\n",
    ")\n",
    "\n",
    "OptimizationAgent=ConversationAgent(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    name_agent=\"OptimizationAgent\",\n",
    "    description=\"Agent to optimize code\",\n",
    "    system_prompt=OPTIMIZER_SYSTEMPROMPT\n",
    ")\n",
    "\n",
    "# Manager Agents\n",
    "manager=AgentManager(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    list_agents=[\n",
    "        CodeDeveloper,         \n",
    "        UIDesignDeveloper,     \n",
    "        OptimizationAgent,     \n",
    "        TesterDeveloper        \n",
    "    ],\n",
    "    system_prompt=COORDINATOR_SYSTEMPROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.run(\"Create a snake game\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws-multiagent-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
