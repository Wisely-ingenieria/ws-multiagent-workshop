{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Administrador de agentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código permite la creación de un sistema para gestionar y coordinar diferentes agentes. En el ejemplo se muestra la capacidad del coordinador para escoger el mejor agente para realizar una tarea especifica.\n",
    "\n",
    "Esencialmente, `AgentManager` actúa como un coordinador, interpretando los mensajes de los usuarios, eligiendo el agente más adecuado para responder a esa solicitud, y pasando el mensaje a ese agente para su procesamiento. También gestiona cualquier interacción subsiguiente entre los agentes y el usuario, manejando la memoria compartida del diálogo para mantener un contexto coherente durante la conversación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Importaciones y configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "from exec_code import execute_code, extract_code_from_string\n",
    "from prompt import CODE_DEVELOPER_SYSTEMPROMPT, DOCUMENTATION_DEVELOPER_SYSTEMPROMPT, COORDINATOR_SYSTEMPROMPT\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Definición de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(ABC):\n",
    "    \n",
    "    def __init__(self, \n",
    "        model: Optional[str] = None, \n",
    "        system_prompt: Optional[str] = None\n",
    "    ) -> None:\n",
    "        \n",
    "        model = model if model else os.getenv(\"OPENAI_DEFAULT_MODEL\")\n",
    "        \n",
    "        self.memory = []\n",
    "        self.model = model\n",
    "        \n",
    "        if system_prompt:\n",
    "            self.memory.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    def add_to_memory(self, role, message):\n",
    "        self.memory.append({\"role\": role, \"content\": message})\n",
    "\n",
    "    def get_schema(self):\n",
    "        return self.function\n",
    "        \n",
    "    @abstractmethod\n",
    "    def run(self,prompt):\n",
    "        \"\"\"User must define this method. Run the agent\"\"\"\n",
    "    \n",
    "class ConversationAgent(Agent):\n",
    "    \n",
    "    def __init__(self, \n",
    "        model: Optional[str] = None, \n",
    "        system_prompt: Optional[str] = None,\n",
    "        agent_name: Optional[str] = None,\n",
    "        description: Optional[str] = None\n",
    "    ) -> None:\n",
    "        super().__init__(model,system_prompt)\n",
    "\n",
    "        self.agent_name = agent_name\n",
    "        self.description = description\n",
    "\n",
    "        self.function={\n",
    "            \"name\": self.agent_name,\n",
    "            \"description\": self.description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"user_prompt\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"User prompt to the agent\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"user_query\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def run(self,prompt):\n",
    "\n",
    "        self.add_to_memory(\"user\", prompt)\n",
    "        completion=''\n",
    "        stream = client.chat.completions.create(\n",
    "            messages=self.memory,\n",
    "            model=self.model,\n",
    "            stream=True\n",
    "        )\n",
    "        print(f\"\\n{self.agent_name}:\")\n",
    "        for chunk in stream:\n",
    "            text_chunk=chunk.choices[0].delta.content\n",
    "            if text_chunk:\n",
    "                completion+=text_chunk\n",
    "                print(text_chunk, end='', flush=True)\n",
    "        \n",
    "        self.add_to_memory(\"assistant\", completion)\n",
    "        \n",
    "        return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Configuración del AgentManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `AgentManager` es una clase que hereda de la clase abstracta `Agent`. Esta clase está diseñada para orquestar y manejar las interacciones entre varios agentes conversacionales, como `CodeDeveloper`, `ImproveDeveloper` y `DocumentationDeveloper`. Cada uno de estos agentes tiene funciones especializadas, como generación de código, diseño de interfaces de usuario, y creación de documentación, respectivamente.\n",
    "\n",
    "Aquí están los elementos clave de la clase `AgentManager`:\n",
    "\n",
    "- **run**: El método `run` es donde se lleva a cabo la lógica principal del `AgentManager`. Cuando se llama a `run` con un mensaje de usuario:\n",
    "  1. Añade el mensaje a la memoria del `AgentManager`.\n",
    "  2. Decide cuál de los agentes debe manejar esta solicitud basándose en su comprensión del mensaje y la lista de agentes disponibles.\n",
    "  3. Basándose en esta información, selecciona el agente adecuado y le pasa la solicitud.\n",
    "  4. El método continúa y ejecuta el agente seleccionado, esperando su respuesta. Si la respuesta contiene código para ejecutar, intenta ejecutar este código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AgentManager(Agent):\n",
    "    \n",
    "    def __init__(self, \n",
    "        model: Optional[str] = None, \n",
    "        system_prompt: Optional[str] = None,\n",
    "        list_agents: Optional[list] = None\n",
    "    ) -> None:\n",
    "        super().__init__(model,system_prompt)\n",
    "        \n",
    "        self.list_agents=list_agents\n",
    "    \n",
    "    \n",
    "    def get_agent_list_schemas(self):\n",
    "        return [agent.get_schema() for agent in self.list_agents]   \n",
    "    \n",
    "    def run(self,prompt):\n",
    "        \n",
    "        print(f\"----------------- RUN MANAGER -----------------\")\n",
    "        print(f\"User: {prompt}\")\n",
    "                            \n",
    "        # Choose what agent i have to execute to resolve the problem (Select speaker)\n",
    "        ######################################\n",
    "        messages = self.memory + [{\"role\": \"user\", \"content\": f\"[PROMPT]\\n{prompt}\\n\\n[AGENTS]\\n{self.get_agent_list_schemas()}\"}]\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=self.model,\n",
    "            functions=self.get_agent_list_schemas()\n",
    "        )\n",
    "                \n",
    "        # Get the agent to execute\n",
    "        agent_name=chat_completion.choices[0].message.function_call.name\n",
    "        agent_prompt=json.loads(chat_completion.choices[0].message.function_call.arguments)['user_prompt']\n",
    "         \n",
    "        #get the class agent to execute\n",
    "        class_agent = next((agent for agent in self.list_agents if agent.agent_name == agent_name), None)\n",
    "        \n",
    "        # Save agents and remove the agent choosen to another list. It is use to store memory in the future in all agents without the agent choosen\n",
    "        other_agents = [agent for agent in self.list_agents if agent.agent_name != agent_name]\n",
    "        \n",
    "        # Add the prompt to the agent manager memory and the others agents\n",
    "        ######################################\n",
    "        self.add_to_memory(\"user\", prompt)\n",
    "        # add memory to others agents\n",
    "        for agent in self.list_agents:\n",
    "            agent.add_to_memory(\"user\", agent_prompt)\n",
    "            \n",
    "        #Execute the algorithm\n",
    "        ######################################\n",
    "            \n",
    "        # # Run agent\n",
    "        ######################################\n",
    "        response_agent=class_agent.run(f\"{class_agent.agent_name}: {agent_prompt}\")\n",
    "        # add memory to others agents\n",
    "        for agent in other_agents:\n",
    "            agent.add_to_memory(\"user\", f\"{class_agent.agent_name}: {response_agent}\")\n",
    "        \n",
    "        # if we have code to execute, execute it\n",
    "        ######################################\n",
    "        code_to_execute = extract_code_from_string(response_agent)\n",
    "        \n",
    "        if code_to_execute:\n",
    "            for i in range(3):\n",
    "                try:\n",
    "                    print(\"Executing code...\")\n",
    "                    exec_response = execute_code(code_to_execute,use_docker=False)\n",
    "                    if exec_response[0] == 0:\n",
    "                        print(f\"Code executed successfully\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"The code: {code_to_execute}.\\n\\nError executing code: {exec_response[1]}\")\n",
    "                        agent_prompt=f\"\\n\\nError executing code: {exec_response[1]}\"\n",
    "                except Exception as e:\n",
    "                    print(f\"The code: {code_to_execute}.\\n\\nError executing code: {e}\")\n",
    "                    agent_prompt=f\"\\n\\nError executing code: {e}\"\n",
    "        else:\n",
    "            print(f\"\\n\\nNo code found to execute.\")\n",
    "            agent_prompt=f\"\\n\\nNo code found to execute.\"\n",
    "        \n",
    "        # Add the response from the agent manager to the memory\n",
    "        ######################################\n",
    "        self.add_to_memory(\"assistant\", response_agent)\n",
    "                \n",
    "        return response_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 - Configuración de los agentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tres agentes, `CodeDeveloper`, `ImproveDeveloper` y `DocumentationDeveloper`, son subclases especializadas de `ConversationAgent`, cada una equipada para manejar diferentes tipos de solicitudes mediante el `system_prompt` que se haya configurado:\n",
    "\n",
    "- **CodeDeveloper**: Genera código en respuesta a problemas o solicitudes de programación proporcionados por el usuario. Su propósito es interactuar con los usuarios que necesitan asistencia en la creación de scripts o software.\n",
    "\n",
    "- **ImproveDeveloper**: Atiende solicitudes relacionadas con el el mejoramiento diseño. Este agente ofrece soluciones o propuestas de diseño para que las interfaces sean más efectivas y atractivas.\n",
    "\n",
    "- **DocumentationDeveloper**: Se especializa en la creación de documentación para código o proyectos de software. Este agente ayuda a los usuarios a redactar una documentación clara y comprensible, importante para cualquier proyecto de desarrollo.\n",
    "\n",
    "- **AgentManager**: Es el coordinador central que gestiona qué agente, desde su listado de agentes, debe responder a una solicitud específica. Interpreta los mensajes del usuario, selecciona al agente más adecuado basándose en la naturaleza del mensaje y la especialización del agente, y redirige la solicitud a ese agente para su procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CodeDeveloper=ConversationAgent(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    agent_name=\"CodeDeveloper\",\n",
    "    description=\"Agent to create code in python\",\n",
    "    system_prompt=CODE_DEVELOPER_SYSTEMPROMPT\n",
    ")\n",
    "\n",
    "ImproveDeveloper=ConversationAgent(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    agent_name=\"ImproveDeveloper\",\n",
    "    description=\"Agent to resolve improvements in python\",\n",
    "    system_prompt=CODE_DEVELOPER_SYSTEMPROMPT\n",
    ")\n",
    "\n",
    "DocumentationDeveloper=ConversationAgent(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    agent_name=\"DocumentationDeveloper\",\n",
    "    description=\"Agent to document code\",\n",
    "    system_prompt=DOCUMENTATION_DEVELOPER_SYSTEMPROMPT\n",
    ")\n",
    "\n",
    "# Manager Agents\n",
    "manager=AgentManager(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    list_agents=[\n",
    "        CodeDeveloper,\n",
    "        DocumentationDeveloper,\n",
    "        ImproveDeveloper\n",
    "    ],\n",
    "    system_prompt=COORDINATOR_SYSTEMPROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5- Ejecutar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- RUN MANAGER -----------------\n",
      "User: Create a code for a face detector using my camera, show me it in display and it must run by 30 sec and end.\n",
      "\n",
      "CodeDeveloper:\n",
      "Certainly. Below is a Python script using OpenCV that accesses your camera, detects faces in real-time, and displays the video feed with detected faces in a window. The script runs for 30 seconds and then automatically stops and closes the video window.\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "import time\n",
      "\n",
      "# Load the pre-trained Haar Cascade face detection model\n",
      "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "\n",
      "# Initialize the camera capture\n",
      "cap = cv2.VideoCapture(0)\n",
      "\n",
      "# Set the start time\n",
      "start_time = time.time()\n",
      "\n",
      "while True:\n",
      "    # Capture frame-by-frame\n",
      "    ret, frame = cap.read()\n",
      "    if not ret:\n",
      "        break  # If frame not captured successfully, break the loop\n",
      "\n",
      "    # Convert to grayscale for face detection\n",
      "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    # Detect faces in the frame\n",
      "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
      "\n",
      "    # Draw rectangles around the faces\n",
      "    for (x, y, w, h) in faces:\n",
      "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
      "\n",
      "    # Display the resulting frame with detected faces\n",
      "    cv2.imshow('Face Detection', frame)\n",
      "\n",
      "    # Exit the loop after 30 seconds\n",
      "    if time.time() - start_time > 30:\n",
      "        break\n",
      "\n",
      "    # Break the loop when 'q' is pressed\n",
      "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "        break\n",
      "\n",
      "# When everything is done, release the capture and destroy all windows\n",
      "cap.release()\n",
      "cv2.destroyAllWindows()\n",
      "```\n",
      "\n",
      "Make sure you have the OpenCV library installed in your Python environment. You can install it using pip:\n",
      "\n",
      "```\n",
      "pip install opencv-python\n",
      "```Executing code...\n",
      "Code executed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Certainly. Below is a Python script using OpenCV that accesses your camera, detects faces in real-time, and displays the video feed with detected faces in a window. The script runs for 30 seconds and then automatically stops and closes the video window.\\n\\n```python\\nimport cv2\\nimport time\\n\\n# Load the pre-trained Haar Cascade face detection model\\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\\n\\n# Initialize the camera capture\\ncap = cv2.VideoCapture(0)\\n\\n# Set the start time\\nstart_time = time.time()\\n\\nwhile True:\\n    # Capture frame-by-frame\\n    ret, frame = cap.read()\\n    if not ret:\\n        break  # If frame not captured successfully, break the loop\\n\\n    # Convert to grayscale for face detection\\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n\\n    # Detect faces in the frame\\n    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\\n\\n    # Draw rectangles around the faces\\n    for (x, y, w, h) in faces:\\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\\n\\n    # Display the resulting frame with detected faces\\n    cv2.imshow('Face Detection', frame)\\n\\n    # Exit the loop after 30 seconds\\n    if time.time() - start_time > 30:\\n        break\\n\\n    # Break the loop when 'q' is pressed\\n    if cv2.waitKey(1) & 0xFF == ord('q'):\\n        break\\n\\n# When everything is done, release the capture and destroy all windows\\ncap.release()\\ncv2.destroyAllWindows()\\n```\\n\\nMake sure you have the OpenCV library installed in your Python environment. You can install it using pip:\\n\\n```\\npip install opencv-python\\n```\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "manager.run(\"Create a code for a face detector using my camera, show me it in display and it must run by 30 sec and end.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- RUN MANAGER -----------------\n",
      "User: Improve the display of the app with better visual design, such as counting faces and coloring the inner faces of the box and adding opacity to it.\n",
      "\n",
      "ImproveDeveloper:\n",
      "```python\n",
      "import cv2\n",
      "import time\n",
      "import numpy as np\n",
      "\n",
      "# Load the pre-trained Haar Cascade face detection model\n",
      "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
      "\n",
      "# Initialize the camera capture\n",
      "cap = cv2.VideoCapture(0)\n",
      "\n",
      "# Set the start time\n",
      "start_time = time.time()\n",
      "\n",
      "# Initialize the face counter\n",
      "face_counter = 0\n",
      "\n",
      "# Define the color and opacity for face overlay\n",
      "overlay_color = (255, 0, 0)\n",
      "opacity = 0.5\n",
      "\n",
      "while True:\n",
      "    # Capture frame-by-frame\n",
      "    ret, frame = cap.read()\n",
      "    if not ret:\n",
      "        break  # If frame not captured successfully, break the loop\n",
      "\n",
      "    # Convert to grayscale for face detection\n",
      "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "    # Detect faces in the frame\n",
      "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
      "\n",
      "    # Draw and fill rectangles around the faces with opacity\n",
      "    for (x, y, w, h) in faces:\n",
      "        # Create a colored overlay\n",
      "        overlay = frame.copy()\n",
      "        cv2.rectangle(overlay, (x, y), (x+w, y+h), overlay_color, -1)  # Filled rectangle with solid color\n",
      "\n",
      "        # Apply the overlay with the specified opacity\n",
      "        cv2.addWeighted(overlay, opacity, frame, 1 - opacity, 0, frame)\n",
      "\n",
      "        # Draw a border for the face\n",
      "        cv2.rectangle(frame, (x, y), (x+w, y+h), overlay_color, 2)\n",
      "\n",
      "    # Count the detected faces\n",
      "    face_counter = len(faces)\n",
      "\n",
      "    # Display the face count on the frame\n",
      "    cv2.putText(frame, f'Faces: {face_counter}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
      "\n",
      "    # Display the resulting frame with detected faces\n",
      "    cv2.imshow('Face Detection', frame)\n",
      "\n",
      "    # Exit the loop after 30 seconds\n",
      "    if time.time() - start_time > 30:\n",
      "        break\n",
      "\n",
      "    # Break the loop when 'q' is pressed\n",
      "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "        break\n",
      "\n",
      "# When everything is done, release the capture and destroy all windows\n",
      "cap.release()\n",
      "cv2.destroyAllWindows()\n",
      "```Executing code...\n",
      "Code executed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"```python\\nimport cv2\\nimport time\\nimport numpy as np\\n\\n# Load the pre-trained Haar Cascade face detection model\\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\\n\\n# Initialize the camera capture\\ncap = cv2.VideoCapture(0)\\n\\n# Set the start time\\nstart_time = time.time()\\n\\n# Initialize the face counter\\nface_counter = 0\\n\\n# Define the color and opacity for face overlay\\noverlay_color = (255, 0, 0)\\nopacity = 0.5\\n\\nwhile True:\\n    # Capture frame-by-frame\\n    ret, frame = cap.read()\\n    if not ret:\\n        break  # If frame not captured successfully, break the loop\\n\\n    # Convert to grayscale for face detection\\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\\n\\n    # Detect faces in the frame\\n    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\\n\\n    # Draw and fill rectangles around the faces with opacity\\n    for (x, y, w, h) in faces:\\n        # Create a colored overlay\\n        overlay = frame.copy()\\n        cv2.rectangle(overlay, (x, y), (x+w, y+h), overlay_color, -1)  # Filled rectangle with solid color\\n\\n        # Apply the overlay with the specified opacity\\n        cv2.addWeighted(overlay, opacity, frame, 1 - opacity, 0, frame)\\n\\n        # Draw a border for the face\\n        cv2.rectangle(frame, (x, y), (x+w, y+h), overlay_color, 2)\\n\\n    # Count the detected faces\\n    face_counter = len(faces)\\n\\n    # Display the face count on the frame\\n    cv2.putText(frame, f'Faces: {face_counter}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\\n\\n    # Display the resulting frame with detected faces\\n    cv2.imshow('Face Detection', frame)\\n\\n    # Exit the loop after 30 seconds\\n    if time.time() - start_time > 30:\\n        break\\n\\n    # Break the loop when 'q' is pressed\\n    if cv2.waitKey(1) & 0xFF == ord('q'):\\n        break\\n\\n# When everything is done, release the capture and destroy all windows\\ncap.release()\\ncv2.destroyAllWindows()\\n```\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.run(\"Improve the display of the app with better visual design, such as counting faces and coloring the inner faces of the box and adding opacity to it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- RUN MANAGER -----------------\n",
      "User: All code before, document the code and explain it\n",
      "\n",
      "DocumentationDeveloper:\n",
      "Title: Real-Time Face Detection with Visual Enhancements\n",
      "\n",
      "Overview:\n",
      "This Python script performs real-time face detection using the OpenCV library. It accesses the user's camera to capture video frames, detects faces in those frames, and visually enhances the output with a colored fill and a face count display. The detection continues for a duration of 30 seconds and then halts automatically, closing the video window.\n",
      "\n",
      "Libraries Used:\n",
      "- OpenCV (cv2): For camera capture, face detection, and graphical display functions.\n",
      "- Time: To control the script's run duration.\n",
      "- NumPy: Used indirectly by OpenCV for array operations.\n",
      "\n",
      "Key Components:\n",
      "- `face_cascade`: An OpenCV Cascade Classifier loaded with Haar cascade data for frontal face detection.\n",
      "- `cap`: VideoCapture object that initializes the camera for video capture.\n",
      "- `start_time`: Records the starting time to manage a 30-second run duration.\n",
      "\n",
      "Operation:\n",
      "1. The camera is accessed and initialized for video frame capture.\n",
      "2. The current time is recorded to track the 30-second operational duration.\n",
      "3. Inside a loop, video frames are captured in real-time.\n",
      "4. Each frame is converted to grayscale, which is a prerequisite for the Haar cascade detector.\n",
      "5. The Haar cascade detector is applied to the grayscale frames to identify face regions.\n",
      "6. For each detected face, a colored, semi-transparent overlay is created with user-defined color and opacity.\n",
      "7. The number of detected faces is counted and displayed on the top-left corner of the frame.\n",
      "8. An output window is continuously updated with the latest frame showing detected faces with graphical enhancements.\n",
      "9. The program checks for the elapsed time and exits the loop once 30 seconds have passed.\n",
      "10. It also listens for the 'q' key press to allow the user to quit the program manually.\n",
      "11. The camera and all created windows are released and destroyed upon exiting the loop.\n",
      "\n",
      "Usage:\n",
      "- Ensure OpenCV is installed in the Python environment (`pip install opencv-python`).\n",
      "- Run the script in a Python environment.\n",
      "- A window will appear, showing the live video feed with detected faces highlighted with a colored overlay and a count of detected faces.\n",
      "- The application will close automatically after 30 seconds or can be manually exited by pressing the 'q' key.\n",
      "\n",
      "Restrictions:\n",
      "- The script assumes a functioning camera is connected to the system.\n",
      "- The Haar cascade model used is most effective for frontal face detection and may not work as well with profile faces.\n",
      "- The script has a fixed duration of 30 seconds after which it will stop automatically.\n",
      "- The exit key is hardcoded to 'q' and there isn't a GUI control to stop the detection other than this keyboard interaction.\n",
      "- Performance and accuracy can vary based on lighting conditions and the quality of the camera.No code found to execute.\n",
      "\n",
      "DocumentationDeveloper:\n",
      "Apologies for the confusion in the previous response. Below is the documentation for the improved Python code for the real-time face detection application using OpenCV, which includes visual enhancements for counting faces and applying colored overlays with opacity on detected faces.\n",
      "\n",
      "---\n",
      "\n",
      "## Real-Time Face Detection with Visual Enhancements using OpenCV\n",
      "\n",
      "### Description\n",
      "This script performs real-time face detection through a webcam or camera module using OpenCV. It enhances the user experience by applying a semi-transparent colored overlay on detected faces and displays a live count of the number of faces detected in the video feed. The application runs for a fixed duration of 30 seconds, after which it automatically terminates and closes the display window.\n",
      "\n",
      "### Dependencies\n",
      "- OpenCV (cv2)\n",
      "- time (Python built-in library)\n",
      "- numpy (implicitly used by OpenCV)\n",
      "\n",
      "### Features\n",
      "- Real-time video capture from the primary camera.\n",
      "- Face detection using Haar Cascade Classifier.\n",
      "- Colored overlay with adjustable opacity on detected faces.\n",
      "- Display of the current count of detected faces on the video feed.\n",
      "- Auto-termination of the application after 30 seconds.\n",
      "\n",
      "### Usage Instructions\n",
      "1. Ensure OpenCV is installed (`pip install opencv-python`).\n",
      "2. Execute the script in a Python environment.\n",
      "3. Observe the video feed with detected faces outlined and shaded.\n",
      "4. Notice the face count displayed on the top left of the video feed.\n",
      "5. Wait for the program to close automatically after 30 seconds or press 'q' to exit early.\n",
      "\n",
      "### Code Functionality\n",
      "- Initialization of the Haar Cascade Classifier for face detection.\n",
      "- Video capture is started using OpenCV’s `VideoCapture` function.\n",
      "- A loop captures the video frame-by-frame and processes each frame to detect faces.\n",
      "- Detected faces are overlaid with a rectangle filled with the desired color and opacity.\n",
      "- The count of detected faces is updated and displayed with each frame.\n",
      "- The loop exits, and resources are cleaned up after 30 seconds or when 'q' is pressed.\n",
      "\n",
      "### Parameters\n",
      "- `overlay_color`: RGB tuple defining the color of the face overlay.\n",
      "- `opacity`: Float value representing the opacity level of the overlay (0 for transparent, 1 for opaque).\n",
      "\n",
      "### Limitations\n",
      "- The script is dependent on the availability and quality of the Haar Cascade Classifier provided by OpenCV.\n",
      "- The performance is constrained by the hardware of the host computer and the specifications of the camera.\n",
      "- The face detection might be less effective in poor lighting or if faces are partially obscured or turned away from the camera.\n",
      "- The script duration is hard-coded to 30 seconds, any changes require modifications to the script.\n",
      "- The application does not cater to face detection at different angles or non-frontal facial features.\n",
      "\n",
      "---\n",
      "\n",
      "This documentation comprehensively describes the operational features, usage, and constraints of the face detection script, ensuring users and developers are well informed about its behavior and capabilities.No code found to execute.\n",
      "\n",
      "DocumentationDeveloper:\n",
      "I apologize for the confusion earlier. Below is the documentation for the previously provided Python script which implements real-time face detection with visual enhancements:\n",
      "\n",
      "---\n",
      "\n",
      "# Real-Time Face Detection with Visual Enhancements\n",
      "\n",
      "## Description\n",
      "This documentation is for a Python script that performs real-time face detection using the OpenCV library. The script accesses the webcam to detect faces within the video stream and applies a semi-transparent colored overlay over each detected face. Additionally, it displays a counter on the video feed indicating the total number of faces detected. The detection process runs for 30 seconds and then the program automatically stops and closes the video feed window.\n",
      "\n",
      "## Requirements\n",
      "- OpenCV: The Open Source Computer Vision Library, which supports various computer vision tasks, including facial detection.\n",
      "- NumPy: A library for the Python programming language, adding support for large, multi-dimensional arrays and matrices.\n",
      "- A webcam or camera connected to the computer running the script.\n",
      "\n",
      "## Features\n",
      "- Accesses the computer's default camera to gather video input.\n",
      "- Employs the Haar Cascade Classifier for detecting faces in the video feed.\n",
      "- Enhances the display by drawing a filled rectangle with specified opacity on detected faces.\n",
      "- Superimposes the count of detected faces on the video feed.\n",
      "- Closes the streaming window automatically after 30 seconds of execution.\n",
      "\n",
      "## Details of the Script\n",
      "- The Haar Cascade face detection model is loaded from OpenCV's pre-trained models.\n",
      "- A `VideoCapture` object is initialized to read frames from the default camera.\n",
      "- For each frame, the image is converted to grayscale to prepare for face detection.\n",
      "- Detected faces are highlighted with a colored overlay, combined with the original frame using weighted addition to achieve the desired opacity.\n",
      "- A continually updated counter displays the number of faces detected on the screen.\n",
      "- After running for the specified duration of 30 seconds, the script automatically ends the video capture by releasing the capture object and destroying all OpenCV windows.\n",
      "\n",
      "## Usage\n",
      "- Before running the script, OpenCV must be installed in the Python environment using the pip package manager with the `pip install opencv-python` command.\n",
      "- To start face detection, run the script in a Python environment.\n",
      "- A window will display the video feed with the visual enhancements applied to detected faces.\n",
      "- The number of detected faces will be updated in real-time at the top-left corner of the video feed.\n",
      "- After 30 seconds, the video feed window will close, or the user can manually close the window by pressing the 'q' key.\n",
      "\n",
      "## Code Execution\n",
      "- Execute the script using a Python interpreter.\n",
      "- No additional command-line arguments are required as the script is self-contained.\n",
      "\n",
      "## Limitations\n",
      "- The script is designed to run for a fixed time period (30 seconds) and is not adjustable without altering the code.\n",
      "- Face detection may be affected by varying lighting conditions, the camera's quality, or the faces' orientation toward the camera.\n",
      "- The script does not implement any additional functionality beyond the fixed duration operation and output display.\n",
      "\n",
      "\n",
      "This documentation provides the necessary information for a user or developer to understand and use the face detection script.No code found to execute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I apologize for the confusion earlier. Below is the documentation for the previously provided Python script which implements real-time face detection with visual enhancements:\\n\\n---\\n\\n# Real-Time Face Detection with Visual Enhancements\\n\\n## Description\\nThis documentation is for a Python script that performs real-time face detection using the OpenCV library. The script accesses the webcam to detect faces within the video stream and applies a semi-transparent colored overlay over each detected face. Additionally, it displays a counter on the video feed indicating the total number of faces detected. The detection process runs for 30 seconds and then the program automatically stops and closes the video feed window.\\n\\n## Requirements\\n- OpenCV: The Open Source Computer Vision Library, which supports various computer vision tasks, including facial detection.\\n- NumPy: A library for the Python programming language, adding support for large, multi-dimensional arrays and matrices.\\n- A webcam or camera connected to the computer running the script.\\n\\n## Features\\n- Accesses the computer's default camera to gather video input.\\n- Employs the Haar Cascade Classifier for detecting faces in the video feed.\\n- Enhances the display by drawing a filled rectangle with specified opacity on detected faces.\\n- Superimposes the count of detected faces on the video feed.\\n- Closes the streaming window automatically after 30 seconds of execution.\\n\\n## Details of the Script\\n- The Haar Cascade face detection model is loaded from OpenCV's pre-trained models.\\n- A `VideoCapture` object is initialized to read frames from the default camera.\\n- For each frame, the image is converted to grayscale to prepare for face detection.\\n- Detected faces are highlighted with a colored overlay, combined with the original frame using weighted addition to achieve the desired opacity.\\n- A continually updated counter displays the number of faces detected on the screen.\\n- After running for the specified duration of 30 seconds, the script automatically ends the video capture by releasing the capture object and destroying all OpenCV windows.\\n\\n## Usage\\n- Before running the script, OpenCV must be installed in the Python environment using the pip package manager with the `pip install opencv-python` command.\\n- To start face detection, run the script in a Python environment.\\n- A window will display the video feed with the visual enhancements applied to detected faces.\\n- The number of detected faces will be updated in real-time at the top-left corner of the video feed.\\n- After 30 seconds, the video feed window will close, or the user can manually close the window by pressing the 'q' key.\\n\\n## Code Execution\\n- Execute the script using a Python interpreter.\\n- No additional command-line arguments are required as the script is self-contained.\\n\\n## Limitations\\n- The script is designed to run for a fixed time period (30 seconds) and is not adjustable without altering the code.\\n- Face detection may be affected by varying lighting conditions, the camera's quality, or the faces' orientation toward the camera.\\n- The script does not implement any additional functionality beyond the fixed duration operation and output display.\\n\\n\\nThis documentation provides the necessary information for a user or developer to understand and use the face detection script.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.run(\"All code before, document the code and explain it\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws-multiagent-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
